# 統計検定準1級 第1章 定理・定義・公式まとめ（用語解説付き）

## 目次
1. [確率の基礎](#1-確率の基礎)
2. [確率変数と確率分布](#2-確率変数と確率分布)
3. [離散確率分布](#3-離散確率分布)
4. [連続確率分布](#4-連続確率分布)
5. [標本分布](#5-標本分布)
6. [中心極限定理](#6-中心極限定理)
7. [大数の法則](#7-大数の法則)
8. [確率の不等式](#8-確率の不等式)

---

## 1. 確率の基礎

### 1.1 確率の定義

#### 用語解説
- **事象**: 確率実験の結果として起こりうる出来事
- **標本空間（Ω）**: 起こりうる全ての結果の集合
- **全事象**: 標本空間全体（必ず起こる事象）

#### 定義：確率
事象Aの確率P(A)は以下の性質を満たす：
1. $0 \leq P(A) \leq 1$
2. $P(\Omega) = 1$（全事象の確率は1）
3. 互いに素な事象$A_1, A_2, \ldots$に対して
   $$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$$

**用語解説**:
- **互いに素**: 2つの事象A, Bが同時に起こることがないこと（$A \cap B = \emptyset$）
- **和事象（∪）**: 事象AまたはBが起こること（$A \cup B$）
- **積事象（∩）**: 事象AとBが同時に起こること（$A \cap B$）

**導入方法**:
確率の直感的な概念を数学的に厳密化。有限個の事象の場合は：
$$P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i)$$

#### 定義：条件付き確率
$$P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0$$

**用語解説**:
- **条件付き確率**: 事象Bが起こったという条件の下での事象Aの確率
- **条件**: 既に起こった事象Bを前提とした確率

**導入方法**:
事象Bが起こったという条件の下での事象Aの確率。具体例：
- サイコロを2回振る
- 1回目が偶数（事象B）の条件下で、2回目も偶数（事象A）の確率
- $P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{1/4}{1/2} = \frac{1}{2}$

#### 定理：ベイズの定理
$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

**用語解説**:
- **事前確率**: 事象Aが起こる確率P(A)
- **事後確率**: 事象Bが起こった後の事象Aの確率P(A|B)
- **尤度**: 事象Aが起こった条件下での事象Bの確率P(B|A)

**導入方法**:

**詳細な導出**:
ベイズの定理は条件付き確率の定義から導出される。以下の手順で丁寧に導出する：

**ステップ1**: 条件付き確率の定義を確認
$$P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0$$

**ステップ2**: 同様にP(B|A)も定義される
$$P(B|A) = \frac{P(A \cap B)}{P(A)}, \quad P(A) > 0$$

**ステップ3**: 両方の式にP(A∩B)が含まれることに注目
$$P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$$

**ステップ4**: 右辺同士を等号で結ぶ
$$P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$$

**ステップ5**: 両辺をP(B)で割る
$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

**具体例による理解**:
- 病気の診断問題を考える
- A: 病気にかかっている事象
- B: 検査で陽性が出る事象
- P(A): 病気の罹患率（事前確率）
- P(B|A): 病気の人が陽性になる確率（感度）
- P(A|B): 陽性の人が実際に病気の確率（事後確率）

**全確率の公式との組み合わせ**:
分母のP(B)は全確率の公式で計算できる：
$$P(B) = P(B|A)P(A) + P(B|A^c)P(A^c)$$
ここで$A^c$はAの補事象（病気でない事象）


条件付き確率の定義から直接導出：
$$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B|A)P(A)}{P(B)}$$

#### 定理：全確率の公式
互いに素な事象$A_1, A_2, \ldots, A_n$で$\bigcup_{i=1}^{n} A_i = \Omega$なら：
$$P(B) = \sum_{i=1}^{n} P(B|A_i)P(A_i)$$

**用語解説**:
- **全確率の公式**: 事象Bの確率を、互いに素な事象$A_i$に分割して計算する公式
- **完全分割**: 互いに素で、全体の和が標本空間になる事象の組

**導入方法**:

**詳細な導出**:
全確率の公式を丁寧に導出する：

**ステップ1**: 前提条件を確認
- $A_i \cap A_j = \emptyset$ for $i \neq j$（互いに素）
- $\bigcup_{i=1}^{n} A_i = \Omega$（完全分割）

**ステップ2**: 事象Bを標本空間との積で表す
$$B = B \cap \Omega$$

**ステップ3**: 完全分割の条件を利用
$$B = B \cap \left(\bigcup_{i=1}^{n} A_i\right)$$

**ステップ4**: 分配法則を適用
$$B = \bigcup_{i=1}^{n} (B \cap A_i)$$

**ステップ5**: 確率の性質を適用
$$P(B) = P\left(\bigcup_{i=1}^{n} (B \cap A_i)\right)$$

**ステップ6**: 互いに素な事象の確率の加法性
$$P\left(\bigcup_{i=1}^{n} (B \cap A_i)\right) = \sum_{i=1}^{n} P(B \cap A_i)$$

**ステップ7**: 条件付き確率の定義を利用
$$P(B \cap A_i) = P(B|A_i)P(A_i)$$

**ステップ8**: 代入して完成
$$P(B) = \sum_{i=1}^{n} P(B|A_i)P(A_i)$$

**直感的な理解**:
- 事象Bを複数の互いに素な事象$A_i$に分割
- 各$A_i$の条件下でのBの確率を重み付き平均
- 重みは各$A_i$の確率

**具体例**:
工場の製品の不良率を計算：
- $A_1$: 機械1で製造（確率0.6）
- $A_2$: 機械2で製造（確率0.4）
- $B$: 不良品
- $P(B|A_1) = 0.02$（機械1の不良率）
- $P(B|A_2) = 0.05$（機械2の不良率）

**計算**:
$$P(B) = P(B|A_1)P(A_1) + P(B|A_2)P(A_2) = 0.02 \times 0.6 + 0.05 \times 0.4 = 0.032$$

**ベイズの定理との関係**:
全確率の公式はベイズの定理の分母で使用される：
$$P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(B|A)P(A)}{\sum_{i=1}^{n} P(B|A_i)P(A_i)}$$

**応用**:
- ベイズの定理の計算
- 条件付き確率の計算
- 統計的推論


事象Bを互いに素な事象$A_i$に分割：
$$P(B) = P(B \cap \Omega) = P\left(B \cap \bigcup_{i=1}^{n} A_i\right) = P\left(\bigcup_{i=1}^{n} (B \cap A_i)\right) = \sum_{i=1}^{n} P(B \cap A_i) = \sum_{i=1}^{n} P(B|A_i)P(A_i)$$

#### 定義：事象の独立性
事象AとBが独立であるとは：
$$P(A \cap B) = P(A)P(B)$$

**用語解説**:
- **独立性**: 一方の事象の発生が他方の確率に影響しない性質
- **統計的独立性**: 確率的に無関係であること

**導入方法**:
一方の事象の発生が他方の確率に影響しない。条件付き確率との関係：
$$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)P(B)}{P(B)} = P(A)$$

---

## 2. 確率変数と確率分布

### 2.1 確率変数の定義

#### 用語解説
- **確率変数**: 標本空間の各結果に実数を対応させる関数
- **離散確率変数**: 取り得る値が有限個または可算無限個
- **連続確率変数**: 取り得る値が連続的な範囲

#### 定義：確率変数
標本空間Ωから実数への関数X: Ω → ℝ

#### 定義：累積分布関数（CDF）
$$F_X(x) = P(X \leq x)$$

**用語解説**:
- **累積分布関数**: 確率変数がx以下である確率
- **分布関数**: 確率分布の完全な情報を含む関数

**性質**:
1. $F_X(x)$は単調非減少
2. $\lim_{x \to -\infty} F_X(x) = 0$, $\lim_{x \to \infty} F_X(x) = 1$
3. 右連続

**導入方法**:
確率変数の値がx以下である確率。離散の場合は：
$$F_X(x) = \sum_{k \leq x} P(X = k)$$

#### 定義：確率密度関数（PDF）
連続確率変数Xに対して：
$$f_X(x) = \frac{d}{dx}F_X(x)$$

**用語解説**:
- **確率密度関数**: 連続確率変数の確率密度を表す関数
- **確率密度**: 微小区間での確率の密度

**性質**:
1. $f_X(x) \geq 0$ for all $x$
2. $\int_{-\infty}^{\infty} f_X(x) dx = 1$
3. $P(a < X \leq b) = \int_a^b f_X(x) dx$

**導入方法**:
累積分布関数の導関数。確率密度の概念：
$$P(x < X \leq x + \Delta x) \approx f_X(x) \Delta x$$

#### 定義：確率質量関数（PMF）
離散確率変数Xに対して：
$$p_X(x) = P(X = x)$$

**用語解説**:
- **確率質量関数**: 離散確率変数の各値での確率
- **確率質量**: 離散点での確率の集中

**性質**:
1. $p_X(x) \geq 0$ for all $x$
2. $\sum_{x} p_X(x) = 1$
3. $P(X \in A) = \sum_{x \in A} p_X(x)$

### 2.2 期待値と分散

#### 用語解説
- **期待値**: 確率変数の平均的な値
- **分散**: 確率変数のばらつきの大きさ
- **標準偏差**: 分散の平方根（元の確率変数と同じ単位）

#### 定義：期待値
- **離散**: $E[X] = \sum_{i} x_i p_X(x_i)$
- **連続**: $E[X] = \int_{-\infty}^{\infty} x f_X(x) dx$

**導入方法**:
確率変数の平均値。離散の場合の直感的理解：
$$E[X] = \sum_{i} x_i \cdot \frac{\text{事象の回数}}{\text{総試行回数}}$$

#### 定義：分散
$$Var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$

**用語解説**:
- **分散**: 期待値からの偏差の二乗の期待値
- **偏差**: 各値と期待値の差

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


期待値からの偏差の二乗の期待値：
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2] = E[X^2] - 2\mu E[X] + \mu^2 = E[X^2] - \mu^2$$

#### 定義：共分散
$$Cov(X,Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]$$

**用語解説**:
- **共分散**: 2つの確率変数の同時変動を測る指標
- **同時変動**: 一方が大きいとき他方も大きい（または小さい）傾向

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


2つの確率変数の同時変動を測る：
$$Cov(X,Y) = E[XY] - E[X]E[Y] = E[XY] - \mu_X \mu_Y$$

#### 定義：相関係数
$$\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$

**用語解説**:
- **相関係数**: 共分散を標準化した指標（-1から1の範囲）
- **正の相関**: 一方が大きいとき他方も大きい傾向
- **負の相関**: 一方が大きいとき他方は小さい傾向

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


共分散を標準化して-1から1の範囲に：
$$\rho_{XY} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$$

---

## 3. 離散確率分布

### 3.1 ベルヌーイ分布

#### 用語解説
- **ベルヌーイ試行**: 成功・失敗の2つの結果しかない試行
- **成功確率**: 成功が起こる確率p
- **失敗確率**: 失敗が起こる確率1-p

#### 定義：ベルヌーイ分布 Bern(p)
成功確率pの1回の試行

**確率質量関数**:
$$P(X = k) = p^k(1-p)^{1-k}, \quad k \in \{0,1\}$$

**期待値**: $E[X] = p$

**分散**: $Var(X) = p(1-p)$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


最も基本的な確率分布。成功を1、失敗を0で表す：
$$E[X] = 1 \cdot p + 0 \cdot (1-p) = p$$
$$Var(X) = E[X^2] - (E[X])^2 = 1^2 \cdot p + 0^2 \cdot (1-p) - p^2 = p - p^2 = p(1-p)$$

### 3.2 二項分布

#### 用語解説
- **二項分布**: n回の独立なベルヌーイ試行の成功回数
- **独立試行**: 各試行の結果が他に影響しない
- **二項係数**: $\binom{n}{k} = \frac{n!}{k!(n-k)!}$

#### 定義：二項分布 B(n,p)
n回の独立なベルヌーイ試行の成功回数

**確率質量関数**:
$$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}, \quad k = 0,1,2,\ldots,n$$

**期待値**: $E[X] = np$

**分散**: $Var(X) = np(1-p)$

**導入方法**:

**詳細な導出**:

**期待値の導出**:
二項分布の期待値を丁寧に導出する：

**方法1: 定義から直接計算**
$$E[X] = \sum_{k=0}^{n} k \cdot P(X = k) = \sum_{k=0}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ1**: k=0の項は0なので、k=1から開始
$$E[X] = \sum_{k=1}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ2**: 二項係数の性質を利用
$$k \binom{n}{k} = k \cdot \frac{n!}{k!(n-k)!} = \frac{n!}{(k-1)!(n-k)!} = n \binom{n-1}{k-1}$$

**ステップ3**: 代入して整理
$$E[X] = \sum_{k=1}^{n} n \binom{n-1}{k-1}p^k(1-p)^{n-k} = np \sum_{k=1}^{n} \binom{n-1}{k-1}p^{k-1}(1-p)^{n-k}$$

**ステップ4**: 変数変換（j = k-1）
$$E[X] = np \sum_{j=0}^{n-1} \binom{n-1}{j}p^j(1-p)^{n-1-j} = np \cdot 1 = np$$

**方法2: 独立和として導出**
$$X = X_1 + X_2 + \cdots + X_n$$
ここで$X_i \sim Bern(p)$（独立）

**ステップ1**: 期待値の線形性を利用
$$E[X] = E[X_1 + X_2 + \cdots + X_n] = E[X_1] + E[X_2] + \cdots + E[X_n]$$

**ステップ2**: 各$X_i$の期待値はp
$$E[X] = p + p + \cdots + p = np$$

**分散の導出**:
**方法1: 独立和として導出**
$$Var(X) = Var(X_1 + X_2 + \cdots + X_n)$$

**ステップ1**: 独立な確率変数の和の分散は分散の和
$$Var(X) = Var(X_1) + Var(X_2) + \cdots + Var(X_n)$$

**ステップ2**: 各$X_i$の分散はp(1-p)
$$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p) = np(1-p)$$



**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


ベルヌーイ分布の独立和として導出：
$$E[X] = E[X_1 + X_2 + \cdots + X_n] = E[X_1] + E[X_2] + \cdots + E[X_n] = p + p + \cdots + p = np$$
$$Var(X) = Var(X_1 + X_2 + \cdots + X_n) = Var(X_1) + Var(X_2) + \cdots + Var(X_n) = p(1-p) + \cdots + p(1-p) = np(1-p)$$

#### 定理：デ・モアブル-ラプラスの定理
$$\frac{X - np}{\sqrt{np(1-p)}} \xrightarrow{d} N(0,1) \quad (n \to \infty)$$

**用語解説**:
- **正規近似**: 二項分布を正規分布で近似すること
- **収束**: 確率変数の列がある分布に近づくこと

**導入方法**:

**詳細な導出**:

**期待値の導出**:
二項分布の期待値を丁寧に導出する：

**方法1: 定義から直接計算**
$$E[X] = \sum_{k=0}^{n} k \cdot P(X = k) = \sum_{k=0}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ1**: k=0の項は0なので、k=1から開始
$$E[X] = \sum_{k=1}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ2**: 二項係数の性質を利用
$$k \binom{n}{k} = k \cdot \frac{n!}{k!(n-k)!} = \frac{n!}{(k-1)!(n-k)!} = n \binom{n-1}{k-1}$$

**ステップ3**: 代入して整理
$$E[X] = \sum_{k=1}^{n} n \binom{n-1}{k-1}p^k(1-p)^{n-k} = np \sum_{k=1}^{n} \binom{n-1}{k-1}p^{k-1}(1-p)^{n-k}$$

**ステップ4**: 変数変換（j = k-1）
$$E[X] = np \sum_{j=0}^{n-1} \binom{n-1}{j}p^j(1-p)^{n-1-j} = np \cdot 1 = np$$

**方法2: 独立和として導出**
$$X = X_1 + X_2 + \cdots + X_n$$
ここで$X_i \sim Bern(p)$（独立）

**ステップ1**: 期待値の線形性を利用
$$E[X] = E[X_1 + X_2 + \cdots + X_n] = E[X_1] + E[X_2] + \cdots + E[X_n]$$

**ステップ2**: 各$X_i$の期待値はp
$$E[X] = p + p + \cdots + p = np$$

**分散の導出**:
**方法1: 独立和として導出**
$$Var(X) = Var(X_1 + X_2 + \cdots + X_n)$$

**ステップ1**: 独立な確率変数の和の分散は分散の和
$$Var(X) = Var(X_1) + Var(X_2) + \cdots + Var(X_n)$$

**ステップ2**: 各$X_i$の分散はp(1-p)
$$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p) = np(1-p)$$


二項分布の確率質量関数の極限：
$$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k} \approx \frac{1}{\sqrt{2\pi np(1-p)}}e^{-\frac{(k-np)^2}{2np(1-p)}}$$

### 3.3 ポアソン分布

#### 用語解説
- **ポアソン過程**: 単位時間あたりの事象発生がランダムな過程
- **レート**: 単位時間あたりの平均発生回数λ
- **稀な事象**: 発生確率が小さい事象

#### 定義：ポアソン分布 Po(λ)
単位時間あたりの事象発生回数

**確率質量関数**:
$$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0,1,2,\ldots$$

**期待値**: $E[X] = \lambda$

**分散**: $Var(X) = \lambda$

**導入方法**:

**詳細な導出**:
ポアソン分布を二項分布の極限として丁寧に導出する：

**前提条件**:
- $n \to \infty$
- $p \to 0$
- $np \to \lambda$（一定）

**ステップ1**: 二項分布の確率質量関数を確認
$$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ2**: 二項係数を展開
$$\binom{n}{k} = \frac{n!}{k!(n-k)!} = \frac{n(n-1)\cdots(n-k+1)}{k!}$$

**ステップ3**: 代入して整理
$$P(X = k) = \frac{n(n-1)\cdots(n-k+1)}{k!}p^k(1-p)^{n-k}$$

**ステップ4**: $p = \frac{\lambda}{n}$を代入
$$P(X = k) = \frac{n(n-1)\cdots(n-k+1)}{k!}\left(\frac{\lambda}{n}\right)^k\left(1-\frac{\lambda}{n}\right)^{n-k}$$

**ステップ5**: 項を分離
$$P(X = k) = \frac{n(n-1)\cdots(n-k+1)}{n^k} \cdot \frac{\lambda^k}{k!} \cdot \left(1-\frac{\lambda}{n}\right)^n \cdot \left(1-\frac{\lambda}{n}\right)^{-k}$$

**ステップ6**: 各項の極限を計算

**項1**: $\lim_{n \to \infty} \frac{n(n-1)\cdots(n-k+1)}{n^k} = 1$

**項2**: $\frac{\lambda^k}{k!}$（nに依存しない）

**項3**: $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^n = e^{-\lambda}$

**項4**: $\lim_{n \to \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$

**ステップ7**: 極限を適用
$$\lim_{n \to \infty} P(X = k) = 1 \cdot \frac{\lambda^k}{k!} \cdot e^{-\lambda} \cdot 1 = \frac{\lambda^k e^{-\lambda}}{k!}$$

**期待値の導出**:
$$E[X] = \sum_{k=0}^{\infty} k \cdot \frac{\lambda^k e^{-\lambda}}{k!} = e^{-\lambda} \sum_{k=1}^{\infty} k \cdot \frac{\lambda^k}{k!}$$

**ステップ1**: k=0の項は0なので、k=1から開始
$$E[X] = e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^k}{(k-1)!}$$

**ステップ2**: 変数変換（j = k-1）
$$E[X] = e^{-\lambda} \sum_{j=0}^{\infty} \frac{\lambda^{j+1}}{j!} = \lambda e^{-\lambda} \sum_{j=0}^{\infty} \frac{\lambda^j}{j!} = \lambda e^{-\lambda} \cdot e^{\lambda} = \lambda$$

**分散の導出**:
$$Var(X) = E[X^2] - (E[X])^2 = E[X^2] - \lambda^2$$

**ステップ1**: $E[X^2]$を計算
$$E[X^2] = \sum_{k=0}^{\infty} k^2 \cdot \frac{\lambda^k e^{-\lambda}}{k!}$$

**ステップ2**: $k^2 = k(k-1) + k$を利用
$$E[X^2] = e^{-\lambda} \sum_{k=0}^{\infty} k(k-1) \frac{\lambda^k}{k!} + e^{-\lambda} \sum_{k=0}^{\infty} k \frac{\lambda^k}{k!}$$

**ステップ3**: 第二項は既に計算済み（λ）
$$E[X^2] = e^{-\lambda} \sum_{k=2}^{\infty} \frac{\lambda^k}{(k-2)!} + \lambda$$

**ステップ4**: 第一項を計算（j = k-2）
$$E[X^2] = e^{-\lambda} \lambda^2 \sum_{j=0}^{\infty} \frac{\lambda^j}{j!} + \lambda = e^{-\lambda} \lambda^2 e^{\lambda} + \lambda = \lambda^2 + \lambda$$

**ステップ5**: 分散を計算
$$Var(X) = \lambda^2 + \lambda - \lambda^2 = \lambda$$



**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


二項分布の極限として導出。$n \to \infty$, $np \to \lambda$のとき：
$$\lim_{n \to \infty} \binom{n}{k}p^k(1-p)^{n-k} = \lim_{n \to \infty} \frac{n!}{k!(n-k)!} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k}$$
$$= \frac{\lambda^k}{k!} \lim_{n \to \infty} \frac{n(n-1)\cdots(n-k+1)}{n^k} \left(1-\frac{\lambda}{n}\right)^n \left(1-\frac{\lambda}{n}\right)^{-k} = \frac{\lambda^k e^{-\lambda}}{k!}$$

#### 定理：ポアソンの極限定理
$$\lim_{n \to \infty, np \to \lambda} B(n,p) = Po(\lambda)$$

### 3.4 幾何分布

#### 用語解説
- **幾何分布**: 最初の成功までの試行回数
- **無記憶性**: 過去の試行結果が将来に影響しない性質
- **幾何級数**: $\sum_{k=1}^{\infty} kx^{k-1} = \frac{1}{(1-x)^2}$ (|x| < 1)

#### 定義：幾何分布 Geom(p)
最初の成功までの試行回数

**確率質量関数**:
$$P(X = k) = (1-p)^{k-1}p, \quad k = 1,2,3,\ldots$$

**期待値**: $E[X] = \frac{1}{p}$

**分散**: $Var(X) = \frac{1-p}{p^2}$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


最初のk-1回は失敗、k回目に成功：
$$P(X = k) = (1-p)^{k-1}p$$
$$E[X] = \sum_{k=1}^{\infty} k(1-p)^{k-1}p = p \sum_{k=1}^{\infty} k(1-p)^{k-1} = p \cdot \frac{1}{[1-(1-p)]^2} = \frac{1}{p}$$

### 3.5 負の二項分布

#### 用語解説
- **負の二項分布**: r回の成功までの試行回数
- **一般化**: 幾何分布の一般化（r=1のとき幾何分布）

#### 定義：負の二項分布 NB(r,p)
r回の成功までの試行回数

**確率質量関数**:
$$P(X = k) = \binom{k-1}{r-1}p^r(1-p)^{k-r}, \quad k = r,r+1,r+2,\ldots$$

**期待値**: $E[X] = \frac{r}{p}$

**分散**: $Var(X) = \frac{r(1-p)}{p^2}$

**導入方法**:

**詳細な導出**:

**期待値の導出**:
二項分布の期待値を丁寧に導出する：

**方法1: 定義から直接計算**
$$E[X] = \sum_{k=0}^{n} k \cdot P(X = k) = \sum_{k=0}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ1**: k=0の項は0なので、k=1から開始
$$E[X] = \sum_{k=1}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ2**: 二項係数の性質を利用
$$k \binom{n}{k} = k \cdot \frac{n!}{k!(n-k)!} = \frac{n!}{(k-1)!(n-k)!} = n \binom{n-1}{k-1}$$

**ステップ3**: 代入して整理
$$E[X] = \sum_{k=1}^{n} n \binom{n-1}{k-1}p^k(1-p)^{n-k} = np \sum_{k=1}^{n} \binom{n-1}{k-1}p^{k-1}(1-p)^{n-k}$$

**ステップ4**: 変数変換（j = k-1）
$$E[X] = np \sum_{j=0}^{n-1} \binom{n-1}{j}p^j(1-p)^{n-1-j} = np \cdot 1 = np$$

**方法2: 独立和として導出**
$$X = X_1 + X_2 + \cdots + X_n$$
ここで$X_i \sim Bern(p)$（独立）

**ステップ1**: 期待値の線形性を利用
$$E[X] = E[X_1 + X_2 + \cdots + X_n] = E[X_1] + E[X_2] + \cdots + E[X_n]$$

**ステップ2**: 各$X_i$の期待値はp
$$E[X] = p + p + \cdots + p = np$$

**分散の導出**:
**方法1: 独立和として導出**
$$Var(X) = Var(X_1 + X_2 + \cdots + X_n)$$

**ステップ1**: 独立な確率変数の和の分散は分散の和
$$Var(X) = Var(X_1) + Var(X_2) + \cdots + Var(X_n)$$

**ステップ2**: 各$X_i$の分散はp(1-p)
$$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p) = np(1-p)$$



**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


r個の幾何分布の和として導出：
$$E[X] = E[Y_1 + Y_2 + \cdots + Y_r] = r \cdot \frac{1}{p} = \frac{r}{p}$$

---

## 4. 連続確率分布

### 4.1 一様分布

#### 用語解説
- **一様分布**: 区間内で等確率で分布
- **等確率**: どの値も同じ確率密度

#### 定義：一様分布 U(a,b)
区間[a,b]で一様に分布

**確率密度関数**:
$$f(x) = \begin{cases}
\frac{1}{b-a} & \text{if } a \leq x \leq b \\
0 & \text{otherwise}
\end{cases}$$

**期待値**: $E[X] = \frac{a+b}{2}$

**分散**: $Var(X) = \frac{(b-a)^2}{12}$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


区間[a,b]で等確率：
$$E[X] = \int_a^b x \cdot \frac{1}{b-a} dx = \frac{1}{b-a} \left[\frac{x^2}{2}\right]_a^b = \frac{b^2-a^2}{2(b-a)} = \frac{a+b}{2}$$

### 4.2 指数分布

#### 用語解説
- **指数分布**: ポアソン過程の待ち時間
- **無記憶性**: 過去の待ち時間が将来に影響しない性質
- **ポアソン過程**: 単位時間あたりの事象発生がランダムな過程

#### 定義：指数分布 Exp(λ)
ポアソン過程の待ち時間

**確率密度関数**:
$$f(x) = \begin{cases}
\lambda e^{-\lambda x} & \text{if } x \geq 0 \\
0 & \text{otherwise}
\end{cases}$$

**期待値**: $E[X] = \frac{1}{\lambda}$

**分散**: $Var(X) = \frac{1}{\lambda^2}$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


ポアソン過程の待ち時間。無記憶性：
$$P(X > s+t | X > s) = P(X > t)$$
$$E[X] = \int_0^{\infty} x \lambda e^{-\lambda x} dx = \left[-x e^{-\lambda x}\right]_0^{\infty} + \int_0^{\infty} e^{-\lambda x} dx = \frac{1}{\lambda}$$

### 4.3 正規分布

#### 用語解説
- **正規分布**: 最も重要な連続確率分布
- **ガウス分布**: 正規分布の別名
- **標準化**: 平均0、分散1に変換すること
- **標準正規分布**: 平均0、分散1の正規分布

#### 定義：正規分布 N(μ,σ²)
最も重要な連続確率分布

**確率密度関数**:
$$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$

**期待値**: $E[X] = \mu$

**分散**: $Var(X) = \sigma^2$

**標準正規分布**: $Z = \frac{X-\mu}{\sigma} \sim N(0,1)$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


中心極限定理から自然に現れる。標準化：
$$Z = \frac{X-\mu}{\sigma} \Rightarrow X = \sigma Z + \mu$$
$$E[X] = E[\sigma Z + \mu] = \sigma E[Z] + \mu = \mu$$

#### 定理：正規分布の再生性
$X_1 \sim N(\mu_1, \sigma_1^2)$, $X_2 \sim N(\mu_2, \sigma_2^2)$ が独立なら：
$$X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$$

**用語解説**:
- **再生性**: 同じ分布の独立な確率変数の和が同じ分布族に属する性質
- **特性関数**: 確率分布を一意に決定する関数

**導入方法**:
特性関数の積：
$$\phi_{X_1+X_2}(t) = \phi_{X_1}(t) \phi_{X_2}(t) = e^{i\mu_1 t - \frac{\sigma_1^2 t^2}{2}} \cdot e^{i\mu_2 t - \frac{\sigma_2^2 t^2}{2}} = e^{i(\mu_1+\mu_2) t - \frac{(\sigma_1^2+\sigma_2^2) t^2}{2}}$$

### 4.4 ガンマ分布

#### 用語解説
- **ガンマ分布**: 指数分布の一般化
- **ガンマ関数**: $\Gamma(\alpha) = \int_0^{\infty} t^{\alpha-1}e^{-t}dt$
- **形状パラメータ**: α（分布の形状を決める）
- **尺度パラメータ**: β（分布の広がりを決める）

#### 定義：ガンマ分布 Γ(α,β)
指数分布の一般化

**確率密度関数**:
$$f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}, \quad x > 0$$

**期待値**: $E[X] = \frac{\alpha}{\beta}$

**分散**: $Var(X) = \frac{\alpha}{\beta^2}$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


指数分布の独立和。$\alpha = 1$のとき指数分布：
$$E[X] = \int_0^{\infty} x \cdot \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x} dx = \frac{\beta^\alpha}{\Gamma(\alpha)} \int_0^{\infty} x^\alpha e^{-\beta x} dx = \frac{\alpha}{\beta}$$

---

## 5. 標本分布

### 5.1 カイ二乗分布

#### 用語解説
- **カイ二乗分布**: 標準正規分布の二乗和
- **自由度**: 独立な確率変数の個数
- **直交変換**: ベクトルの長さを変えない線形変換

#### 定義：カイ二乗分布 χ²(k)
標準正規分布の二乗和

**確率密度関数**:
$$f(x) = \frac{1}{2^{k/2}\Gamma(k/2)}x^{k/2-1}e^{-x/2}, \quad x > 0$$

**期待値**: $E[X] = k$

**分散**: $Var(X) = 2k$

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


$Z_1^2 + Z_2^2 + \cdots + Z_k^2$ where $Z_i \sim N(0,1)$。ガンマ分布の特殊ケース：
$$\chi^2(k) = \Gamma\left(\frac{k}{2}, \frac{1}{2}\right)$$

#### 定理：正規分布の標本分散
$X_1, X_2, \ldots, X_n \sim N(\mu, \sigma^2)$ が独立なら：
$$\frac{(n-1)S^2}{\sigma^2} = \frac{\sum_{i=1}^n (X_i - \bar{X})^2}{\sigma^2} \sim \chi^2(n-1)$$

**用語解説**:
- **標本分散**: $S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2$
- **不偏分散**: 母分散の不偏推定量

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


直交変換を利用。$Y_i = \frac{X_i - \mu}{\sigma}$とすると：
$$\sum_{i=1}^n Y_i^2 = \sum_{i=1}^n (Y_i - \bar{Y})^2 + n\bar{Y}^2$$
$$\sum_{i=1}^n (Y_i - \bar{Y})^2 \sim \chi^2(n-1)$$

### 5.2 t分布

#### 用語解説
- **t分布**: 標準正規分布とカイ二乗分布の比
- **スチューデントのt分布**: t分布の別名
- **自由度**: カイ二乗分布の自由度

#### 定義：t分布 t(k)
標準正規分布とカイ二乗分布の比

**確率密度関数**:
$$f(x) = \frac{\Gamma((k+1)/2)}{\sqrt{k\pi}\Gamma(k/2)}\left(1+\frac{x^2}{k}\right)^{-(k+1)/2}$$

**期待値**: $E[X] = 0$ (k > 1)

**分散**: $Var(X) = \frac{k}{k-2}$ (k > 2)

**導入方法**:

**詳細な導出**:
分散の公式$Var(X) = E[X^2] - (E[X])^2$を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の線形性を利用して展開
$$Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2]$$
ここで$\mu = E[X]$とする

**ステップ3**: 期待値の線形性により各項を分離
$$E[X^2 - 2\mu X + \mu^2] = E[X^2] - E[2\mu X] + E[\mu^2]$$

**ステップ4**: 定数の期待値と定数倍の期待値を計算
$$E[2\mu X] = 2\mu E[X] = 2\mu^2$$
$$E[\mu^2] = \mu^2$$

**ステップ5**: 代入して整理
$$Var(X) = E[X^2] - 2\mu^2 + \mu^2 = E[X^2] - \mu^2 = E[X^2] - (E[X])^2$$

**直感的な理解**:
- 分散は「平均からの距離の二乗の平均」
- $E[X^2]$: 二乗の平均
- $(E[X])^2$: 平均の二乗
- この差が分散を表す

**具体例**:
サイコロの出目の分散を計算：
- $E[X] = \frac{1+2+3+4+5+6}{6} = 3.5$
- $E[X^2] = \frac{1^2+2^2+3^2+4^2+5^2+6^2}{6} = \frac{91}{6}$
- $Var(X) = \frac{91}{6} - (3.5)^2 = \frac{91}{6} - \frac{49}{4} = \frac{35}{12}$


$\frac{Z}{\sqrt{\chi^2_k/k}}$ where $Z \sim N(0,1)$, $\chi^2_k \sim \chi^2(k)$

#### 定理：スチューデントのt統計量
$X_1, X_2, \ldots, X_n \sim N(\mu, \sigma^2)$ が独立なら：
$$\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$$

**用語解説**:
- **t統計量**: 標本平均の標準化統計量
- **標準誤差**: 標本平均の標準偏差

**導入方法**:
正規分布の平均と分散の独立性：
$$\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0,1), \quad \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$$
$$\frac{\bar{X} - \mu}{S/\sqrt{n}} = \frac{\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2}/(n-1)}} \sim t(n-1)$$

### 5.3 F分布

#### 用語解説
- **F分布**: 2つの独立なカイ二乗分布の比
- **分散比**: 2つの分散の比
- **フィッシャー分布**: F分布の別名

#### 定義：F分布 F(d₁,d₂)
2つの独立なカイ二乗分布の比

**確率密度関数**:
$$f(x) = \frac{\Gamma((d_1+d_2)/2)}{\Gamma(d_1/2)\Gamma(d_2/2)}\left(\frac{d_1}{d_2}\right)^{d_1/2}x^{d_1/2-1}\left(1+\frac{d_1x}{d_2}\right)^{-(d_1+d_2)/2}$$

**期待値**: $E[X] = \frac{d_2}{d_2-2}$ (d₂ > 2)

**導入方法**:
$\frac{\chi^2_{d_1}/d_1}{\chi^2_{d_2}/d_2}$ where $\chi^2_{d_1} \sim \chi^2(d_1)$, $\chi^2_{d_2} \sim \chi^2(d_2)$

---

## 6. 中心極限定理

### 6.1 リンドバーグ-レヴィの中心極限定理

#### 用語解説
- **中心極限定理**: 標本平均が正規分布に収束する定理
- **収束**: 確率変数の列がある分布に近づくこと
- **特性関数**: 確率分布を一意に決定する関数

#### 定理：中心極限定理
独立同分布の確率変数 $X_1, X_2, \ldots, X_n$ について、$E[X_i] = \mu$, $Var(X_i) = \sigma^2 < \infty$ のとき：

$$\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} = \frac{\sqrt{n}(\bar{X} - \mu)}{\sigma} \xrightarrow{d} N(0,1) \quad (n \to \infty)$$

**導入方法**:

**詳細な導出**:
中心極限定理を特性関数を用いて丁寧に導出する：

**ステップ1**: 標準化された確率変数を定義
$$Y_i = \frac{X_i - \mu}{\sigma}, \quad \bar{Y} = \frac{1}{n}\sum_{i=1}^n Y_i$$

**ステップ2**: 目標の確率変数を定義
$$Z_n = \frac{\sqrt{n}(\bar{X} - \mu)}{\sigma} = \sqrt{n}\bar{Y}$$

**ステップ3**: 特性関数を計算
$$\phi_{Z_n}(t) = E[e^{itZ_n}] = E[e^{it\sqrt{n}\bar{Y}}] = E\left[\prod_{i=1}^n e^{itY_i/\sqrt{n}}\right]$$

**ステップ4**: 独立性を利用
$$\phi_{Z_n}(t) = \prod_{i=1}^n E[e^{itY_i/\sqrt{n}}] = [\phi_{Y_i}(t/\sqrt{n})]^n$$

**ステップ5**: $Y_i$の特性関数を展開
$$\phi_{Y_i}(t) = E[e^{itY_i}] = E[e^{it(X_i-\mu)/\sigma}]$$

**ステップ6**: テイラー展開を適用
$$\phi_{Y_i}(t) = 1 + itE[Y_i] + \frac{(it)^2}{2!}E[Y_i^2] + \frac{(it)^3}{3!}E[Y_i^3] + \cdots$$

**ステップ7**: $Y_i$の性質を利用
$$E[Y_i] = 0, \quad E[Y_i^2] = 1, \quad E[Y_i^3] = \frac{E[(X_i-\mu)^3]}{\sigma^3}$$

**ステップ8**: 代入して整理
$$\phi_{Y_i}(t) = 1 - \frac{t^2}{2} + \frac{(it)^3}{6}E[Y_i^3] + o(t^3)$$

**ステップ9**: $t/\sqrt{n}$を代入
$$\phi_{Y_i}(t/\sqrt{n}) = 1 - \frac{t^2}{2n} + \frac{(it)^3}{6n^{3/2}}E[Y_i^3] + o(t^3/n^{3/2})$$

**ステップ10**: 対数を取って展開
$$\log[\phi_{Y_i}(t/\sqrt{n})] = \log\left[1 - \frac{t^2}{2n} + \frac{(it)^3}{6n^{3/2}}E[Y_i^3] + o(t^3/n^{3/2})\right]$$

**ステップ11**: $\log(1+x) = x - \frac{x^2}{2} + \cdots$を利用
$$\log[\phi_{Y_i}(t/\sqrt{n})] = -\frac{t^2}{2n} + \frac{(it)^3}{6n^{3/2}}E[Y_i^3] + o(t^3/n^{3/2})$$

**ステップ12**: $Z_n$の特性関数を計算
$$\log[\phi_{Z_n}(t)] = n \log[\phi_{Y_i}(t/\sqrt{n})] = -\frac{t^2}{2} + \frac{(it)^3}{6\sqrt{n}}E[Y_i^3] + o(t^3/\sqrt{n})$$

**ステップ13**: $n \to \infty$の極限を取る
$$\lim_{n \to \infty} \log[\phi_{Z_n}(t)] = -\frac{t^2}{2}$$

**ステップ14**: 指数を取る
$$\lim_{n \to \infty} \phi_{Z_n}(t) = e^{-t^2/2}$$

**ステップ15**: 標準正規分布の特性関数と一致
$$Z_n \xrightarrow{d} N(0,1)$$

**直感的な理解**:
- 標本平均は正規分布に近づく
- 標本サイズが大きいほど近似が良くなる
- 母分布の形状に関係なく成り立つ

**具体例**:
一様分布U(0,1)からの標本：
- $E[X_i] = 0.5$, $Var(X_i) = 1/12$
- 標本平均$\bar{X}$は$n$が大きいとき$N(0.5, 1/(12n))$に近づく

**応用**:
- 信頼区間の構成
- 仮説検定
- 統計的推論の基礎


特性関数による証明。$Y_i = \frac{X_i - \mu}{\sigma}$とすると：
$$\phi_{Y_i}(t) = 1 - \frac{t^2}{2} + o(t^2)$$
$$\phi_{\frac{\bar{Y}}{\sqrt{n}}}(t) = \left[\phi_{Y_i}\left(\frac{t}{\sqrt{n}}\right)\right]^n = \left[1 - \frac{t^2}{2n} + o\left(\frac{t^2}{n}\right)\right]^n \to e^{-\frac{t^2}{2}}$$

### 6.2 デ・モアブル-ラプラスの定理

#### 定理：デ・モアブル-ラプラスの定理
二項分布の正規近似：

$$\frac{X - np}{\sqrt{np(1-p)}} \xrightarrow{d} N(0,1) \quad (n \to \infty, p \text{ fixed})$$

**導入方法**:

**詳細な導出**:

**期待値の導出**:
二項分布の期待値を丁寧に導出する：

**方法1: 定義から直接計算**
$$E[X] = \sum_{k=0}^{n} k \cdot P(X = k) = \sum_{k=0}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ1**: k=0の項は0なので、k=1から開始
$$E[X] = \sum_{k=1}^{n} k \binom{n}{k}p^k(1-p)^{n-k}$$

**ステップ2**: 二項係数の性質を利用
$$k \binom{n}{k} = k \cdot \frac{n!}{k!(n-k)!} = \frac{n!}{(k-1)!(n-k)!} = n \binom{n-1}{k-1}$$

**ステップ3**: 代入して整理
$$E[X] = \sum_{k=1}^{n} n \binom{n-1}{k-1}p^k(1-p)^{n-k} = np \sum_{k=1}^{n} \binom{n-1}{k-1}p^{k-1}(1-p)^{n-k}$$

**ステップ4**: 変数変換（j = k-1）
$$E[X] = np \sum_{j=0}^{n-1} \binom{n-1}{j}p^j(1-p)^{n-1-j} = np \cdot 1 = np$$

**方法2: 独立和として導出**
$$X = X_1 + X_2 + \cdots + X_n$$
ここで$X_i \sim Bern(p)$（独立）

**ステップ1**: 期待値の線形性を利用
$$E[X] = E[X_1 + X_2 + \cdots + X_n] = E[X_1] + E[X_2] + \cdots + E[X_n]$$

**ステップ2**: 各$X_i$の期待値はp
$$E[X] = p + p + \cdots + p = np$$

**分散の導出**:
**方法1: 独立和として導出**
$$Var(X) = Var(X_1 + X_2 + \cdots + X_n)$$

**ステップ1**: 独立な確率変数の和の分散は分散の和
$$Var(X) = Var(X_1) + Var(X_2) + \cdots + Var(X_n)$$

**ステップ2**: 各$X_i$の分散はp(1-p)
$$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p) = np(1-p)$$


二項分布の確率質量関数の極限：
$$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k} \approx \frac{1}{\sqrt{2\pi np(1-p)}}e^{-\frac{(k-np)^2}{2np(1-p)}}$$

---

## 7. 大数の法則

### 7.1 弱大数の法則

#### 用語解説
- **大数の法則**: 標本平均が母平均に収束する法則
- **弱収束**: 確率収束（確率的に近づく）
- **強収束**: 概収束（ほぼ確実に近づく）

#### 定理：弱大数の法則
独立同分布の確率変数 $X_1, X_2, \ldots$ について、$E[X_i] = \mu < \infty$ のとき：

$$\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \xrightarrow{p} \mu \quad (n \to \infty)$$

**導入方法**:
チェビシェフの不等式を利用：
$$P(|\bar{X}_n - \mu| \geq \epsilon) \leq \frac{Var(\bar{X}_n)}{\epsilon^2} = \frac{Var(X_1)}{n\epsilon^2} \to 0$$

### 7.2 強大数の法則

#### 定理：強大数の法則
同様の条件下で：

$$\bar{X}_n \xrightarrow{a.s.} \mu \quad (n \to \infty)$$

**用語解説**:
- **概収束**: ほぼ確実に収束すること
- **ボレル-カンテリの補題**: 確率論の基本的な補題

**導入方法**:
ボレル-カンテリの補題とマルチンゲール理論を利用

---

## 8. 確率の不等式

### 8.1 チェビシェフの不等式

#### 用語解説
- **チェビシェフの不等式**: 確率の上界を与える不等式
- **上界**: 確率の上限値

#### 定理：チェビシェフの不等式
任意の確率変数 $X$ と $\epsilon > 0$ について：

$$P(|X - E[X]| \geq \epsilon) \leq \frac{Var(X)}{\epsilon^2}$$

**導入方法**:

**詳細な導出**:
チェビシェフの不等式を丁寧に導出する：

**ステップ1**: 分散の定義を確認
$$Var(X) = E[(X - E[X])^2]$$

**ステップ2**: 期待値の定義を利用
$$Var(X) = \int_{-\infty}^{\infty} (x - E[X])^2 f(x) dx$$
ここで$f(x)$は確率密度関数（離散の場合は和に置き換え）

**ステップ3**: 積分範囲を分割
$$Var(X) = \int_{|x - E[X]| < \epsilon} (x - E[X])^2 f(x) dx + \int_{|x - E[X]| \geq \epsilon} (x - E[X])^2 f(x) dx$$

**ステップ4**: 第二項に注目（第一項は非負）
$$Var(X) \geq \int_{|x - E[X]| \geq \epsilon} (x - E[X])^2 f(x) dx$$

**ステップ5**: 積分範囲内で$(x - E[X])^2 \geq \epsilon^2$なので
$$Var(X) \geq \int_{|x - E[X]| \geq \epsilon} \epsilon^2 f(x) dx = \epsilon^2 \int_{|x - E[X]| \geq \epsilon} f(x) dx$$

**ステップ6**: 積分は確率を表す
$$\int_{|x - E[X]| \geq \epsilon} f(x) dx = P(|X - E[X]| \geq \epsilon)$$

**ステップ7**: 代入して整理
$$Var(X) \geq \epsilon^2 P(|X - E[X]| \geq \epsilon)$$

**ステップ8**: 両辺を$\epsilon^2$で割る
$$P(|X - E[X]| \geq \epsilon) \leq \frac{Var(X)}{\epsilon^2}$$

**直感的な理解**:
- 分散が小さいほど、期待値から大きく離れる確率は小さい
- $\epsilon$が大きいほど、不等式は緩くなる
- 確率の上界を与える有用な不等式

**具体例**:
サイコロの出目について：
- $E[X] = 3.5$, $Var(X) = \frac{35}{12}$
- $\epsilon = 2$のとき：
  $$P(|X - 3.5| \geq 2) \leq \frac{35/12}{4} = \frac{35}{48} \approx 0.729$$
- 実際の確率：$P(X \leq 1.5) + P(X \geq 5.5) = P(X = 1) + P(X = 6) = \frac{1}{3} \approx 0.333$

**応用**:
- 大数の法則の証明
- 統計的推論での確率の評価
- 異常値の検出


分散の定義から直接導出：
$$Var(X) = E[(X - E[X])^2] \geq E[(X - E[X])^2 \mathbf{1}_{|X - E[X]| \geq \epsilon}] \geq \epsilon^2 P(|X - E[X]| \geq \epsilon)$$

### 8.2 マルコフの不等式

#### 定理：マルコフの不等式
非負確率変数 $X$ と $\epsilon > 0$ について：

$$P(X \geq \epsilon) \leq \frac{E[X]}{\epsilon}$$

**導入方法**:
期待値の定義から直接導出：
$$E[X] = \int_0^{\infty} x f(x) dx \geq \int_{\epsilon}^{\infty} x f(x) dx \geq \epsilon \int_{\epsilon}^{\infty} f(x) dx = \epsilon P(X \geq \epsilon)$$

### 8.3 コーシー-シュワルツの不等式

#### 定理：コーシー-シュワルツの不等式
任意の確率変数 $X$, $Y$ について：

$$|E[XY]| \leq \sqrt{E[X^2]E[Y^2]}$$

**導入方法**:
二次形式の非負性：
$$E[(aX + bY)^2] = a^2 E[X^2] + 2ab E[XY] + b^2 E[Y^2] \geq 0$$
判別式 $D = 4(E[XY])^2 - 4E[X^2]E[Y^2] \leq 0$ より導出

---

## まとめ

第1章では、確率論の基礎から始まり、主要な確率分布、極限定理までを扱います。これらの概念は統計学の基盤となる重要な内容です。

### 学習のポイント
1. **確率の基礎**: 条件付き確率、ベイズの定理、全確率の公式
2. **確率分布**: 各分布の特徴と関係性
3. **極限定理**: 中心極限定理と大数の法則の重要性
4. **不等式**: 確率の上界を与える基本的な道具

### 実践的な学習方法
1. **定義の理解**: 各概念の数学的定義を正確に把握
2. **導出の習得**: 定理や公式の導出過程を理解
3. **具体例**: 実際のデータで概念を確認
4. **演習問題**: 多様な問題を解いて定着
